{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: gpt2...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import streamlit as st\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "\n",
    "# Install necessary libraries\n",
    "try:\n",
    "    import transformers\n",
    "except ImportError:\n",
    "    os.system(\"pip install transformers\")\n",
    "    import transformers\n",
    "\n",
    "import os\n",
    "HUGGINGFACE_TOKEN = os.getenv(\"HUGGINGFACE_TOKEN\")\n",
    "\n",
    "\n",
    "\n",
    "# Select a model (Modify this based on resources)\n",
    "AVAILABLE_MODELS = {\n",
    "    \"gpt2\": \"gpt2\",\n",
    "    \"gpt-neo\": \"EleutherAI/gpt-neo-1.3B\",\n",
    "    \"opt\": \"facebook/opt-1.3b\"\n",
    "}\n",
    "\n",
    "MODEL_NAME = AVAILABLE_MODELS[\"gpt2\"]  # Change this key to load a different model\n",
    "\n",
    "# Load tokenizer and model\n",
    "print(f\"Loading model: {MODEL_NAME}...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(prompt, max_length=50, temperature=0.7, top_p=0.9):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    outputs = model.generate(\n",
    "        input_ids=inputs[\"input_ids\"],  # Explicitly set input_ids\n",
    "        attention_mask=inputs[\"attention_mask\"],  # Add attention mask for better output\n",
    "        max_length=max_length,\n",
    "        temperature=temperature,\n",
    "        top_p=top_p,\n",
    "        do_sample=True  # Enables sampling for more varied responses\n",
    "    )\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete. Model and tokenizer are ready.\n",
      "Loaded model: gpt2\n",
      "Chatbot is ready! Type 'exit' to stop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: my name is dayo-sama, that's what I'm thinking.\"\n",
      "\n",
      "\"Oh? What is it?\"\n",
      "\n",
      "\"I'm not sure what it's called, but I thought I would ask about it.\"\n",
      "\n",
      "\"But what is it?\"\n",
      "\n",
      "\"Well, I have an account, but it's not really a account. It's just something I can transfer to any account. It's a simple form that I can use to transfer things to other accounts.\"\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: i am from USA so I'm not sure if it's the same type of thing.\n",
      "\n",
      "As for the \"Halloween-like\" feeling, I'm not sure. I don't know. Maybe I'm just a bit off about this. Maybe I'm just a bit off about this. Maybe I'm just a bit off about this.\n",
      "\n",
      "So, for now, I'm just going to keep going with my usual approach. I'm not going to be too hard on myself\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: DAVEWORLD NA MY GUY 1 0.25 0.25 0.25 1.25 0.25 0.25 0.25 0.25 0.25 0.25 1.25 0.25 0.25 0.25 0.25 0.25 0.25 0.25 0.25 0.25 0.25 0.25 0.25 0.25 0.25 0.25 0.25 0.25 0.25 0.25 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: daveworld is my friend and I'll be sharing with you the details of this upcoming adventure.\n",
      "\n",
      "I'm starting off with a lot of the details for this adventure. First off, there is a new version of the story that takes place in my home town of The Darkside. There is a new story called The Darkside Story which is a new world where you can learn a lot about the world and the people of this world. The Darkside Story is going to\n",
      "Chatbot: Goodbye!\n"
     ]
    }
   ],
   "source": [
    "# Chatbot Interface\n",
    "def chatbot():\n",
    "    \"\"\"\n",
    "    Implements a simple chatbot loop that interacts with the user.\n",
    "    - Type 'exit' to end the conversation.\n",
    "    \"\"\"\n",
    "    print(\"Chatbot is ready! Type 'exit' to stop.\")\n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.strip() == \"\":\n",
    "            print(\"Chatbot: Please enter a valid input.\")\n",
    "            continue\n",
    "        if user_input.lower() == \"exit\":\n",
    "            print(\"Chatbot: Goodbye!\")\n",
    "            break\n",
    "        \n",
    "        try:\n",
    "            response = generate_text(user_input, temperature=0.8, max_length=100)\n",
    "        except Exception as e:\n",
    "            response = f\"Error processing input: {e}\"\n",
    "        \n",
    "        print(f\"Chatbot: {response}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Setup complete. Model and tokenizer are ready.\")\n",
    "    print(f\"Loaded model: {MODEL_NAME}\")\n",
    "    chatbot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete. Model and tokenizer are ready.\n",
      "Loaded model: gpt2\n",
      "Chatbot is ready! Type 'exit' to stop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Hello-Verse:\n",
      "\n",
      "This is how the Godly Spirit lives!\n",
      "\n",
      "Now we know that God is a God.\n",
      "\n",
      "Now we know that God is not only a God, but also a human being.\n",
      "\n",
      "Now we know that God is not only a human being, but also a God.\n",
      "\n",
      "And so it is that we are all that we are.\n",
      "\n",
      "Now we know that God is not only a human being, but also a God.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Tell me a joke,\" he says. \"I was pretty pissed that we were going to be getting the job. The whole thing was so much fun. It was like, 'Wow, it was great!'\"\n",
      "\n",
      "In the end, the story turned out to be a bit of a fluke. A few hours after the audition, the team was offered an offer to work on the film for a year, and with a few days to go on it, the team was able to make a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Goodbye!\n",
      "\n",
      "Running chatbot test cases...\n",
      "You: Hello!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Hello!\n",
      "\n",
      "\"Hm?\"\n",
      "\n",
      "\"You're not a woman.\"\n",
      "\n",
      "\"You're a woman?\"\n",
      "\n",
      "\"Yes, I am.\"\n",
      "\n",
      "\"What?\"\n",
      "\n",
      "\"Why are you speaking to me?\"\n",
      "\n",
      "\"I can't speak. Why? You're not a woman!\"\n",
      "\n",
      "\"Why are you speaking to me? What's wrong with you? You're not a woman.\"\n",
      "\n",
      "\"You're not a woman?\"\n",
      "\n",
      "\"I'm\n",
      "\n",
      "You: Tell me a joke.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Tell me a joke. Why would I take this kind of stuff? How do I know that I'm not going to be a jerk?\n",
      "\n",
      "I think it's a really good question. There's a whole world of stuff out there that doesn't work. And that's really what the problem is. You think there's going to be some guy who is going to put it all together and tell me what to do. There's a lot of things that we don't do that we're\n",
      "\n",
      "You: What is AI?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: What is AI?\n",
      "\n",
      "AI is the concept of making something from nothing.\n",
      "\n",
      "AI is a new phenomenon in the history of robotics. It is not a new idea. It has been around for a long time.\n",
      "\n",
      "There is a lot of talk about AI and robotics. There is nothing wrong with that. But when you talk about robots, you have to consider how you're going to create something new.\n",
      "\n",
      "The problem is that you have to decide if you want to do\n",
      "\n",
      "You: Can you write a poem?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Can you write a poem?\n",
      "\n",
      "If you have the chance, please ask!\n",
      "\n",
      "What would you like to write?\n",
      "\n",
      "What would you like to write about?\n",
      "\n",
      "What would you like to write about?\n",
      "\n",
      "What would you like to write about?\n",
      "\n",
      "What would you like to write about?\n",
      "\n",
      "What would you like to write about?\n",
      "\n",
      "What would you like to write about?\n",
      "\n",
      "What would you like to write about?\n",
      "\n",
      "What would\n",
      "\n",
      "You: Who is the president of the United States?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Who is the president of the United States?\n",
      "\n",
      "Mr. President, I am very interested in this question. The president of the United States, in the first place, is a member of the United States Senate and I have been very interested in this question. The president of the United States, as you know, is a member of the Senate, and I think you have a right to ask him about this. And so we will have to see how this plays out, but, first of\n",
      "\n",
      "You: Give me a random fact!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Give me a random fact! I'm a man! I'm a man! I'm a man! I'm a man! I'm a man! I'm a man! I'm a man! I'm a man! I'm a man! I'm a man! I'm a man! I'm a man! I'm a man! I'm a man! I'm a man! I'm a man! I'm a man! I'm a man! I'm a man\n",
      "\n",
      "You: exit\n",
      "Chatbot: exit/1) in the following steps:\n",
      "\n",
      "# cd to the server directory and run the following command (e.g., /usr/bin/python2.7)\n",
      "\n",
      "# cp /usr/bin/python2.7/configure cp /usr/bin/python2.7/configure.py\n",
      "\n",
      "# cd to the server directory and run the following command (e.g., /usr/bin/python2.7) # cp /usr\n",
      "\n",
      "Testing complete.\n"
     ]
    }
   ],
   "source": [
    "# Testing and Iteration\n",
    "def test_chatbot():\n",
    "    \"\"\"\n",
    "    Runs predefined test cases to evaluate chatbot performance.\n",
    "    \"\"\"\n",
    "    test_cases = [\n",
    "        \"Hello!\",\n",
    "        \"Tell me a joke.\",\n",
    "        \"What is AI?\",\n",
    "        \"Can you write a poem?\",\n",
    "        \"Who is the president of the United States?\",\n",
    "        \"Give me a random fact!\",\n",
    "        \"exit\"\n",
    "    ]\n",
    "    \n",
    "    print(\"\\nRunning chatbot test cases...\")\n",
    "    for test in test_cases:\n",
    "        print(f\"You: {test}\")\n",
    "        response = generate_text(test, temperature=0.8, max_length=100)\n",
    "        print(f\"Chatbot: {response}\\n\")\n",
    "    print(\"Testing complete.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Setup complete. Model and tokenizer are ready.\")\n",
    "    print(f\"Loaded model: {MODEL_NAME}\")\n",
    "    \n",
    "    # Run chatbot\n",
    "    chatbot()\n",
    "    \n",
    "    # Run test cases after chatbot session\n",
    "    test_chatbot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "HUGGINGFACE_TOKEN = os.getenv(\"HUGGINGFACE_TOKEN\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
