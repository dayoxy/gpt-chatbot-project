{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: gpt2...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import streamlit as st\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# Install necessary libraries\n",
    "try:\n",
    "    import transformers\n",
    "except ImportError:\n",
    "    os.system(\"pip install transformers\")\n",
    "    import transformers\n",
    "\n",
    "# Select a model (Modify this based on resources)\n",
    "AVAILABLE_MODELS = {\n",
    "    \"gpt2\": \"gpt2\",\n",
    "    \"gpt-neo\": \"EleutherAI/gpt-neo-1.3B\",\n",
    "    \"opt\": \"facebook/opt-1.3b\"\n",
    "}\n",
    "\n",
    "MODEL_NAME = AVAILABLE_MODELS[\"gpt2\"]  # Change this key to load a different model\n",
    "\n",
    "# Load tokenizer and model\n",
    "print(f\"Loading model: {MODEL_NAME}...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(prompt, max_length=50, temperature=0.7, top_p=0.9):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    outputs = model.generate(\n",
    "        input_ids=inputs[\"input_ids\"],  # Explicitly set input_ids\n",
    "        attention_mask=inputs[\"attention_mask\"],  # Add attention mask for better output\n",
    "        max_length=max_length,\n",
    "        temperature=temperature,\n",
    "        top_p=top_p,\n",
    "        do_sample=True  # Enables sampling for more varied responses\n",
    "    )\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete. Model and tokenizer are ready.\n",
      "Loaded model: gpt2\n",
      "Chatbot is ready! Type 'exit' to stop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: dayo-san, where we were talking about the future. The last part was about the current state of the game.\n",
      "\n",
      "\"I'm thinking about how we could make it that much better. We would just be able to focus on the best and not have to worry about the worst. But it's not like I'm thinking about how to make it better. It's not like we can just spend a bunch of money and make the best game. It's just that we've got\n",
      "Chatbot: Goodbye!\n"
     ]
    }
   ],
   "source": [
    "# Chatbot Interface\n",
    "def chatbot():\n",
    "    \"\"\"\n",
    "    Implements a simple chatbot loop that interacts with the user.\n",
    "    - Type 'exit' to end the conversation.\n",
    "    \"\"\"\n",
    "    print(\"Chatbot is ready! Type 'exit' to stop.\")\n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.strip() == \"\":\n",
    "            print(\"Chatbot: Please enter a valid input.\")\n",
    "            continue\n",
    "        if user_input.lower() == \"exit\":\n",
    "            print(\"Chatbot: Goodbye!\")\n",
    "            break\n",
    "        \n",
    "        try:\n",
    "            response = generate_text(user_input, temperature=0.8, max_length=100)\n",
    "        except Exception as e:\n",
    "            response = f\"Error processing input: {e}\"\n",
    "        \n",
    "        print(f\"Chatbot: {response}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Setup complete. Model and tokenizer are ready.\")\n",
    "    print(f\"Loaded model: {MODEL_NAME}\")\n",
    "    chatbot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete. Model and tokenizer are ready.\n",
      "Loaded model: gpt2\n",
      "Chatbot is ready! Type 'exit' to stop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: daveworld.com, a site dedicated to the most popular and innovative of the digital age, The Digital Daily. As the main site of the weekly newsletter, the site is designed to provide readers with an updated and accurate account of the world's most important digital developments. We also provide a wide variety of free online news and articles, including news and information about the financial and social media industry.\n",
      "\n",
      "For the latest news, opinion, and information, follow us on Facebook, Twitter, LinkedIn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Goodbye!\n",
      "\n",
      "Running chatbot test cases...\n",
      "You: Hello!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Hello! I hope this helps you. Thank you!\n",
      "\n",
      "We've had a lot of trouble with the website and the website will not be available for a few hours! Please email us at info@wrestlingtickets.com if you have any problems. Thank you!\n",
      "\n",
      "The only way to know if the website is up is to go to www.wrestlingtickets.com and follow the instructions.\n",
      "\n",
      "You: Tell me a joke.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Tell me a joke.\n",
      "\n",
      "I like the word \"giggle\". I like the way people are able to think, or how people act, or how people act. So, I'd like to see a little bit of that.\n",
      "\n",
      "I'm not going to go into too much detail about how you think your body feels.\n",
      "\n",
      "I think it's really good for your body.\n",
      "\n",
      "It's nice to know that.\n",
      "\n",
      "So, how do you feel about that?\n",
      "\n",
      "You: What is AI?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: What is AI?\n",
      "\n",
      "AI is a mathematical concept that was coined by Carl von Clausewitz and is now widely accepted. It is based on mathematical modeling of human behavior and social psychology. AI is designed to be more complex than simple logic but more human-like. It can learn more from other human behavior and may be able to understand other humans' behavior. AI will not always be able to learn from its own mistakes, but it will likely be able to learn from our mistakes, as long\n",
      "\n",
      "You: Can you write a poem?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Can you write a poem?\n",
      "\n",
      "I wrote a poem a few days ago and I felt like I was writing something that I needed to write. But I'm not writing anything because I want to write poetry. I'm writing something that I really want to write. And I don't want to go and do a poetry class because I don't want to go to a poetry class. I want to do a poem that I want to write.\n",
      "\n",
      "Do you think you can write a poem\n",
      "\n",
      "You: Who is the president of the United States?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Who is the president of the United States? That's right,\" he said. \"If you look at our record, I have to say it's the best we've ever had. We've been here a long time and we've been here for over 30 years.\"\n",
      "\n",
      "Trump's first speech to a joint session of Congress on Thursday came in response to a question from Rep. Mick Mulvaney, R-S.C., who asked whether Trump would accept the nomination of his new economic\n",
      "\n",
      "You: Give me a random fact!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Give me a random fact! â€” Barack Obama (@BarackObama) February 3, 2016\n",
      "\n",
      "One of the biggest reasons Obama won the election is because his team ran a winning strategy. The idea was that Obama would be a better president than Hillary Clinton. That's why Obama won by a huge margin.\n",
      "\n",
      "But that was a strategy that did not work. His team has no idea what they're doing. So they just go ahead and run it.\n",
      "\n",
      "Obama was not a bad\n",
      "\n",
      "You: exit\n",
      "Chatbot: exit.\n",
      "\n",
      "In addition, a second option is to leave the existing game, and re-enable the game at any point in time, as long as the player is still playing in the original game.\n",
      "\n",
      "It's worth noting that if the player is in the original game, the original game can be accessed only by the player who left the game, and the old game can also be accessed. If the player is in the original game, then the game is still accessible.\n",
      "\n",
      "\n",
      "\n",
      "Testing complete.\n"
     ]
    }
   ],
   "source": [
    "# Testing and Iteration\n",
    "def test_chatbot():\n",
    "    \"\"\"\n",
    "    Runs predefined test cases to evaluate chatbot performance.\n",
    "    \"\"\"\n",
    "    test_cases = [\n",
    "        \"Hello!\",\n",
    "        \"Tell me a joke.\",\n",
    "        \"What is AI?\",\n",
    "        \"Can you write a poem?\",\n",
    "        \"Who is the president of the United States?\",\n",
    "        \"Give me a random fact!\",\n",
    "        \"exit\"\n",
    "    ]\n",
    "    \n",
    "    print(\"\\nRunning chatbot test cases...\")\n",
    "    for test in test_cases:\n",
    "        print(f\"You: {test}\")\n",
    "        response = generate_text(test, temperature=0.8, max_length=100)\n",
    "        print(f\"Chatbot: {response}\\n\")\n",
    "    print(\"Testing complete.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Setup complete. Model and tokenizer are ready.\")\n",
    "    print(f\"Loaded model: {MODEL_NAME}\")\n",
    "    \n",
    "    # Run chatbot\n",
    "    chatbot()\n",
    "    \n",
    "    # Run test cases after chatbot session\n",
    "    test_chatbot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "HUGGINGFACE_TOKEN = os.getenv(\"HUGGINGFACE_TOKEN\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
