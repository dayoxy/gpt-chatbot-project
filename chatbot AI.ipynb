{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: gpt2...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import streamlit as st\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "try:\n",
    "    import transformers\n",
    "except ImportError:\n",
    "    os.system(\"pip install transformers\")\n",
    "    import transformers\n",
    "\n",
    "# Select a model (Modify this based on resources)\n",
    "AVAILABLE_MODELS = {\n",
    "    \"gpt2\": \"gpt2\",\n",
    "    \"gpt-neo\": \"EleutherAI/gpt-neo-1.3B\",\n",
    "    \"opt\": \"facebook/opt-1.3b\"\n",
    "}\n",
    "\n",
    "MODEL_NAME = AVAILABLE_MODELS[\"gpt2\"]  # Change this key to load a different model\n",
    "\n",
    "# Load tokenizer and model\n",
    "print(f\"Loading model: {MODEL_NAME}...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(prompt, max_length=50, temperature=0.7, top_p=0.9):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    outputs = model.generate(\n",
    "        input_ids=inputs[\"input_ids\"],  # Explicitly set input_ids\n",
    "        attention_mask=inputs[\"attention_mask\"],  # Add attention mask for better output\n",
    "        max_length=max_length,\n",
    "        temperature=temperature,\n",
    "        top_p=top_p,\n",
    "        do_sample=True  # Enables sampling for more varied responses\n",
    "    )\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete. Model and tokenizer are ready.\n",
      "Loaded model: gpt2\n",
      "Chatbot is ready! Type 'exit' to stop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: dayo.\n",
      "\n",
      "\"I was very happy. I don't know how to describe it. We were trying to get it down to that point,\" he said. \"It was all good, but not very good.\"\n",
      "\n",
      "Khan had been trying to figure out how to get past the game with the team before going down with a concussion. He says he was able to recover and fight back through the rest of the game.\n",
      "\n",
      "\"I think it was very clear. I wasn\n",
      "Chatbot: Goodbye!\n"
     ]
    }
   ],
   "source": [
    "# Chatbot Interface\n",
    "def chatbot():\n",
    "    \"\"\"\n",
    "    Implements a simple chatbot loop that interacts with the user.\n",
    "    - Type 'exit' to end the conversation.\n",
    "    \"\"\"\n",
    "    print(\"Chatbot is ready! Type 'exit' to stop.\")\n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.strip() == \"\":\n",
    "            print(\"Chatbot: Please enter a valid input.\")\n",
    "            continue\n",
    "        if user_input.lower() == \"exit\":\n",
    "            print(\"Chatbot: Goodbye!\")\n",
    "            break\n",
    "        \n",
    "        try:\n",
    "            response = generate_text(user_input, temperature=0.8, max_length=100)\n",
    "        except Exception as e:\n",
    "            response = f\"Error processing input: {e}\"\n",
    "        \n",
    "        print(f\"Chatbot: {response}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Setup complete. Model and tokenizer are ready.\")\n",
    "    print(f\"Loaded model: {MODEL_NAME}\")\n",
    "    chatbot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete. Model and tokenizer are ready.\n",
      "Loaded model: gpt2\n",
      "Chatbot is ready! Type 'exit' to stop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: bayo's son, who also works as an officer with the Sheriff's Department.\n",
      "\n",
      "\"This was a very important development,\" said John P. McDonough, deputy director of the National Organization for the Reform of Marijuana Laws. \"It was a very important development.\"\n",
      "\n",
      "In the days after the arrest, the sheriff's office did not say who provided the information.\n",
      "\n",
      "But in a letter sent to the mayor, the sheriff said, \"As a matter of policy, the\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Goodbye!\n",
      "\n",
      "Running chatbot test cases...\n",
      "You: Hello!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Hello! It's time for the final episode of the new episode of The Simpsons, \"The Simpsons: The Adventures of Homer Simpson\", which will air on October 7th on Fox.\n",
      "\n",
      "As you may know, Homer Simpson was the son of a famous character and one of the biggest personalities in the world. After his father's death, he was forced to go to Springfield to live with his mother and stepfather, but he eventually found a new home in Springfield. While there, he met\n",
      "\n",
      "You: Tell me a joke.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Tell me a joke. I'm not going to call the girls names. What do you mean? It's okay to say they're names. They are names, and I'm not going to call them names. Let's get this over with. Let's go.\n",
      "\n",
      "\"I can't get over it. I'm the guy who's going to throw the ball around and get his teammates to think he's a good player. It's a joke. If I ever get a chance to\n",
      "\n",
      "You: What is AI?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: What is AI?\n",
      "\n",
      "AI is a system that learns in a way that will enable us to answer questions. A AI system may be human-like, intelligent, or even just a mixture of both.\n",
      "\n",
      "As AI becomes more complex and complex, the question becomes: How will we best utilize it? What tools will we need to make it better?\n",
      "\n",
      "When you think of AI, you start with the notion of being able to perform tasks without the need to know the answers.\n",
      "\n",
      "You: Can you write a poem?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Can you write a poem?\n",
      "\n",
      "No. It's not going to come out in the end.\n",
      "\n",
      "The fact is, I love the idea of doing a poem. There are times when I'm going to want to write something, and I'm going to say, \"No, that doesn't make sense. Why would you want to write something in the beginning?\"\n",
      "\n",
      "I love that idea. The more you do it, the more you love it.\n",
      "\n",
      "There's something\n",
      "\n",
      "You: Who is the president of the United States?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Who is the president of the United States? What is the Constitution?\"\n",
      "\n",
      "\"That's the question,\" he responded. \"I will tell you what it is. It's called the Constitution.\"\n",
      "\n",
      "Trump's response was in response to a question from MSNBC's Rachel Maddow about his comments on Russian President Vladimir Putin.\n",
      "\n",
      "\"I think you know, Putin is a great leader, but I think he's a very, very good leader,\" Trump said. \"He's going to\n",
      "\n",
      "You: Give me a random fact!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Give me a random fact!\n",
      "\n",
      "- I'm not a fan of you, but I'm glad to hear your name.\n",
      "\n",
      "- Hey, it's the first time I've heard you on the radio, and it sounds like you're a little more than a little different.\n",
      "\n",
      "- Why do you think you're so different?\n",
      "\n",
      "- I think I'm a little more of a \"realist\" than a \"freak\" who thinks it's okay to call me\n",
      "\n",
      "You: exit\n",
      "Chatbot: exit to the east.\n",
      "\n",
      "This is a map of the world that contains all the places that are connected to the city, and the map also shows the areas that are only accessible from the east.\n",
      "\n",
      "In the following maps, you can see the areas that are only accessible from the west, and the areas that are only accessible from the east.\n",
      "\n",
      "Map 3 - A simple map of the world\n",
      "\n",
      "In this map, you can see all the locations that have been assigned to\n",
      "\n",
      "Testing complete.\n"
     ]
    }
   ],
   "source": [
    "# Testing and Iteration\n",
    "def test_chatbot():\n",
    "    \"\"\"\n",
    "    Runs predefined test cases to evaluate chatbot performance.\n",
    "    \"\"\"\n",
    "    test_cases = [\n",
    "        \"Hello!\",\n",
    "        \"Tell me a joke.\",\n",
    "        \"What is AI?\",\n",
    "        \"Can you write a poem?\",\n",
    "        \"Who is the president of the United States?\",\n",
    "        \"Give me a random fact!\",\n",
    "        \"exit\"\n",
    "    ]\n",
    "    \n",
    "    print(\"\\nRunning chatbot test cases...\")\n",
    "    for test in test_cases:\n",
    "        print(f\"You: {test}\")\n",
    "        response = generate_text(test, temperature=0.8, max_length=100)\n",
    "        print(f\"Chatbot: {response}\\n\")\n",
    "    print(\"Testing complete.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Setup complete. Model and tokenizer are ready.\")\n",
    "    print(f\"Loaded model: {MODEL_NAME}\")\n",
    "    \n",
    "    # Run chatbot\n",
    "    chatbot()\n",
    "    \n",
    "    # Run test cases after chatbot session\n",
    "    test_chatbot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "HUGGINGFACE_TOKEN = os.getenv(\"HUGGINGFACE_TOKEN\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
